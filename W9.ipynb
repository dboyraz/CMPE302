{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PirTGsN2tFn1"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Exercise 1\n",
        "# Load Iris dataset from sklearn\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "D-axyh3dwjN0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LR model with 1000 iteration\n",
        "model = LogisticRegression(max_iter = 1000)\n",
        "model.fit(X_train, y_train)\n",
        "prediction = model.predict(X_test)"
      ],
      "metadata": {
        "id": "GawkNkA-wwGU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate accuracy score\n",
        "accuracy = accuracy_score(y_test, prediction)\n",
        "print(\"Logistic regression accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEP45aDXxgnc",
        "outputId": "07c0782d-73f2-4363-b306-dfe7ef6bf4fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression accuracy:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Excercise 2\n",
        "\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create Ridge Model\n",
        "ridge = Ridge(alpha=0.1)\n",
        "ridge.fit(X_train, y_train)\n",
        "ridge_pred = ridge.predict(X_test)\n",
        "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
        "print(\"Ridge model mean squared error: \", ridge_mse)\n",
        "\n",
        "# Create Lasso Model\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X_train, y_train)\n",
        "lasso_pred = lasso.predict(X_test)\n",
        "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
        "print(\"Lasso model mse: \", lasso_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w25qQHsRywEU",
        "outputId": "0a506ee3-18f3-433c-f21a-7383c06b654b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge model mean squared error:  0.03733155605720707\n",
            "Lasso model mse:  0.06677344873438022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Excercise 3\n",
        "# Multiclass Logistic Regression\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Load the dataset (takes a minute)\n",
        "dataset = fetch_openml(name = 'Fashion-MNIST')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQjf0PjW17IU",
        "outputId": "ec60a308-c27a-4797-f774-b61f89db050f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "Xx = dataset.data\n",
        "yy = dataset.target\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(Xx, yy, test_size=0.2, random_state=42)\n",
        "# .... continue next week"
      ],
      "metadata": {
        "id": "JNOEWnCu3eDt"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}